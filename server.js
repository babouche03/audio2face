// server.js - Audio2Face Backend Service
const express = require('express');
const multer = require('multer');
const cors = require('cors');
const fs = require('fs');
const path = require('path');
const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');
const { spawn } = require('child_process');
const yaml = require('js-yaml');

const app = express();
const PORT = 3000;

// ä¸­é—´ä»¶
app.use(cors());
app.use(express.json());

// æ–‡ä»¶ä¸Šä¼ é…ç½®
const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        const uploadDir = './uploads';
        if (!fs.existsSync(uploadDir)) {
            fs.mkdirSync(uploadDir);
        }
        cb(null, uploadDir);
    },
    filename: (req, file, cb) => {
        cb(null, Date.now() + '-' + file.originalname);
    }
});

const upload = multer({ storage: storage });

// æ¨¡å‹é…ç½®
const MODEL_CONFIG = {
    claire: { 
        functionId: '0961a6da-fb9e-4f2e-8491-247e5fd7bf8d',
        config: 'config_claire.yml'
    },
    mark: { 
        functionId: '8efc55f5-6f00-424e-afe9-26212cd2c630',
        config: 'config_mark.yml'
    },
    james: { 
        functionId: '9327c39f-a361-4e02-bd72-e11b4c9b7b5e',
        config: 'config_james.yml'
    }
};

// ä¸»è¦ API ç«¯ç‚¹:å¤„ç†éŸ³é¢‘å¹¶è°ƒç”¨ Audio2Face
app.post('/api/generate-animation', upload.single('audio'), async (req, res) => {
    const { model, apiKey } = req.body;
    const audioFile = req.file;

    console.log('æ”¶åˆ°è¯·æ±‚:', { model, apiKey: apiKey?.substring(0, 20) + '...', audioFile: audioFile?.filename });

    if (!audioFile || !model || !apiKey) {
        return res.status(400).json({ 
            error: 'ç¼ºå°‘å¿…è¦å‚æ•°',
            details: {
                hasAudio: !!audioFile,
                hasModel: !!model,
                hasApiKey: !!apiKey
            }
        });
    }

    try {
        // è½¬æ¢éŸ³é¢‘ä¸º PCM 16-bit WAV
        const pcmAudioPath = await convertToPCM16(audioFile.path);
        console.log('éŸ³é¢‘è½¬æ¢å®Œæˆ:', pcmAudioPath);
        
        // è°ƒç”¨ Audio2Face Python å®¢æˆ·ç«¯
        const animationData = await callAudio2FaceAPI(
            pcmAudioPath,
            model,
            apiKey
        );

        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        fs.unlinkSync(audioFile.path);
        fs.unlinkSync(pcmAudioPath);

        res.json({
            success: true,
            data: animationData
        });

    } catch (error) {
        console.error('å¤„ç†é”™è¯¯:', error);
        res.status(500).json({ 
            error: 'å¤„ç†å¤±è´¥',
            message: error.message 
        });
    }
});

// è½¬æ¢éŸ³é¢‘ä¸º PCM 16-bit WAV (ä½¿ç”¨ ffmpeg)
function convertToPCM16(inputPath) {
    return new Promise((resolve, reject) => {
        const outputPath = inputPath.replace(/\.[^.]+$/, '_pcm.wav');
        console.log(`æ­£åœ¨è½¬æ¢éŸ³é¢‘æ–‡ä»¶: ${inputPath} -> ${outputPath}`);
        const ffmpeg = spawn('ffmpeg', [
            '-i', inputPath,
            '-acodec', 'pcm_s16le',
            '-ar', '16000',
            '-ac', '1',
            '-y',
            outputPath
        ]);

        ffmpeg.on('close', (code) => {
            if (code === 0) {
                console.log(`éŸ³é¢‘è½¬æ¢æˆåŠŸ: ${outputPath}`);
                resolve(outputPath);
            } else {
                reject(new Error(`FFmpeg è½¬æ¢å¤±è´¥,ä»£ç : ${code}`));
            }
        });

        ffmpeg.stderr.on('data', (data) => {
            console.log(`FFmpeg: ${data}`);
        });
    });
}

// è°ƒç”¨ Audio2Face Python å®¢æˆ·ç«¯

function callAudio2FaceAPI(audioPath, model, apiKey) {
    return new Promise((resolve, reject) => {
        const config = MODEL_CONFIG[model];
        if (!config) {
            return reject(new Error('ä¸æ”¯æŒçš„æ¨¡å‹'));
        }

        // â­ å…³é”®ï¼šä½¿ç”¨è™šæ‹Ÿç¯å¢ƒé‡Œçš„ python
        const pythonPath = path.join(
            __dirname,
            'Audio2Face-3D-Samples',
            'myenv311',
            'bin',
            'python'
        );

        const pythonScript = path.join(
            __dirname,
            'Audio2Face-3D-Samples',
            'scripts',
            'audio2face_3d_api_client',
            'nim_a2f_3d_client.py'
        );

        const configFile = path.join(
            __dirname,
            'Audio2Face-3D-Samples',
            'scripts',
            'audio2face_3d_api_client',
            'config',
            config.config
        );

        console.log(`ä½¿ç”¨ Python: ${pythonPath}`);
        console.log(`è°ƒç”¨ Python è„šæœ¬: ${pythonScript}`);

        const python = spawn(pythonPath, [
            pythonScript,
            audioPath,
            configFile,
            '--apikey', apiKey,
            '--function-id', config.functionId
        ]);

        let output = '';
        let errorOutput = '';

        python.stdout.on('data', (data) => {
            output += data.toString();
            console.log(`Python è¾“å‡º: ${data}`);
        });

        python.stderr.on('data', (data) => {
            errorOutput += data.toString();
            console.error(`Python é”™è¯¯: ${data}`);
        });

        python.on('close', (code) => {
            if (code === 0) {
                try {
                    const animationData = parseAnimationOutput(output);
                    resolve(animationData);
                } catch (err) {
                    reject(new Error('è§£æåŠ¨ç”»æ•°æ®å¤±è´¥: ' + err.message));
                }
            } else {
                reject(new Error(`Python è„šæœ¬å¤±è´¥: ${errorOutput}`));
            }
        });
    });
}
// function callAudio2FaceAPI(audioPath, model, apiKey) {
//     return new Promise((resolve, reject) => {
//         const config = MODEL_CONFIG[model];
//         if (!config) {
//             return reject(new Error('ä¸æ”¯æŒçš„æ¨¡å‹'));
//         }

//         const pythonScript = path.join(__dirname, 'Audio2Face-3D-Samples', 'scripts', 'audio2face_3d_api_client', 'nim_a2f_3d_client.py');
//         const configFile = path.join(__dirname, 'audio2face_client', 'config', config.config);

//         console.log(`è°ƒç”¨ Python è„šæœ¬: ${pythonScript}`);
//         console.log(`éŸ³é¢‘è·¯å¾„: ${audioPath}, é…ç½®æ–‡ä»¶: ${configFile}`);

//         const python = spawn('python3', [
//             pythonScript,
//             audioPath,
//             configFile,
//             '--apikey', apiKey,
//             '--function-id', config.functionId,
//             '--output-json'
//         ]);

//         let output = '';
//         let errorOutput = '';

//         python.stdout.on('data', (data) => {
//             output += data.toString();
//             console.log(`Python è¾“å‡º: ${data}`);
//         });

//         python.stderr.on('data', (data) => {
//             errorOutput += data.toString();
//             console.error(`Python é”™è¯¯: ${data}`);
//         });

//         python.on('close', (code) => {
//             if (code === 0) {
//                 try {
//                     const animationData = parseAnimationOutput(output);
//                     console.log('è§£æåçš„åŠ¨ç”»æ•°æ®:', animationData);
//                     resolve(animationData);
//                 } catch (error) {
//                     reject(new Error('è§£æåŠ¨ç”»æ•°æ®å¤±è´¥: ' + error.message));
//                 }
//             } else {
//                 reject(new Error(`Python è„šæœ¬å¤±è´¥: ${errorOutput}`));
//             }
//         });
//     });
// }

// è§£æåŠ¨ç”»è¾“å‡ºæ•°æ®
function parseAnimationOutput(output) {
    // å¦‚æœæ˜¯ JSON æ ¼å¼
    try {
        return JSON.parse(output);
    } catch (e) {
        // å¦‚æœæ˜¯ CSV æ ¼å¼,è§£æ CSV
        const lines = output.split('\n').filter(line => line.trim());
        const blendshapes = [];
        
        for (let i = 1; i < lines.length; i++) { // è·³è¿‡å¤´éƒ¨
            const [name, value, time] = lines[i].split(',');
            if (name && value && time) {
                blendshapes.push({
                    name: name.trim(),
                    value: parseFloat(value),
                    time: parseFloat(time)
                });
            }
        }
        
        return { blendshapes };
    }
}

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/api/health', (req, res) => {
    res.json({ 
        status: 'ok',
        message: 'Audio2Face æœåŠ¡è¿è¡Œä¸­',
        timestamp: new Date().toISOString()
    });
});

// è·å–æ¨¡å‹é…ç½®ç«¯ç‚¹
app.get('/api/model-config/:model', (req, res) => {
    const { model } = req.params;
    const modelConfigs = {
        claire: 'config_claire.yml',
        mark: 'config_mark.yml',
        james: 'config_james.yml'
    };

    const configFile = modelConfigs[model];
    if (!configFile) {
        return res.status(400).json({ error: 'ä¸æ”¯æŒçš„æ¨¡å‹' });
    }

    const configPath = path.join(__dirname, 'audio2face_client', 'config', configFile);
    
    try {
        const yamlContent = fs.readFileSync(configPath, 'utf8');
        const config = yaml.load(yamlContent);
        const blendshapeId = config.a2f?.blendshape_id;
        
        if (!blendshapeId) {
            return res.status(500).json({ 
                error: 'æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘ blendshape_id' 
            });
        }
        
        res.json({
            success: true,
            data: {
                blendshape_id: blendshapeId
            }
        });
    } catch (error) {
        console.error('è¯»å–æ¨¡å‹é…ç½®å¤±è´¥:', error);
        res.status(500).json({  
            error: 'è¯»å–æ¨¡å‹é…ç½®å¤±è´¥',
            message: error.message 
        });
    }
});

// æµ‹è¯•ç«¯ç‚¹:è¿”å›æ¨¡æ‹Ÿæ•°æ®
app.post('/api/test-animation', upload.single('audio'), (req, res) => {
    console.log('æµ‹è¯•æ¨¡å¼:è¿”å›æ¨¡æ‹Ÿæ•°æ®');
    
    // ç”Ÿæˆæ¨¡æ‹Ÿçš„ blendshape åŠ¨ç”»æ•°æ®
    const mockData = {
        blendshapes: [],
        duration: 3.0
    };

    // å¸¸è§çš„ ARKit blendshapes
    const blendshapeNames = [
        'jawOpen', 'mouthSmile', 'mouthPucker', 'mouthFrown',
        'eyeBlinkLeft', 'eyeBlinkRight', 'browInnerUp', 'browOuterUpLeft'
    ];

    // ç”Ÿæˆ 30 å¸§çš„åŠ¨ç”»æ•°æ® (æ¯ç§’ 10 å¸§)
    for (let frame = 0; frame < 30; frame++) {
        const time = frame * 0.1;
        
        blendshapeNames.forEach(name => {
            let value;
            if (name === 'jawOpen') {
                // å˜´å·´å¼€åˆåŠ¨ç”»
                value = Math.abs(Math.sin(frame * 0.5)) * 0.8;
            } else if (name.includes('Smile')) {
                value = Math.random() * 0.3;
            } else {
                value = Math.random() * 0.2;
            }
            
            mockData.blendshapes.push({
                name,
                value,
                time
            });
        });
    }

    res.json({
        success: true,
        data: mockData,
        note: 'è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®,ç”¨äºæµ‹è¯•'
    });
});

// é™æ€æ–‡ä»¶æœåŠ¡ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰ API è·¯ç”±ä¹‹åï¼‰
app.use(express.static('public')); // æä¾›å‰ç«¯æ–‡ä»¶
app.use('/audio2face_client/config', express.static(path.join(__dirname, 'audio2face_client/config')));
app.use('/models', express.static(path.join(__dirname, 'models')));

// å¯åŠ¨æœåŠ¡å™¨
app.listen(PORT, () => {
    console.log(`\nğŸš€ Audio2Face åç«¯æœåŠ¡å·²å¯åŠ¨`);
    console.log(`ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:${PORT}`);
    console.log(`ğŸ§ª æµ‹è¯•ç«¯ç‚¹: http://localhost:${PORT}/api/health`);
    console.log(`ğŸ“ å‰ç«¯æ–‡ä»¶: ./public/index.html\n`);
});

// é”™è¯¯å¤„ç†
process.on('uncaughtException', (error) => {
    console.error('æœªæ•è·çš„å¼‚å¸¸:', error);
});

process.on('unhandledRejection', (reason, promise) => {
    console.error('æœªå¤„ç†çš„ Promise æ‹’ç»:', reason);
});
